from csv import DictReader
from collections import defaultdict
from lxml import etree
from cgi import FieldStorage
from math import log, log10
import json


def value_of(csvDict, header, bin_size = 0):
    """
    csvDict - the dictionary generated by the csvDictReader iterator
    header - one of the headers in the original csv file or "Month", assume valid
    bin_size - required if header needs to be binned, an int representing size of each bin

    returns the processed corresponding value in the dictionary
    """

    if header == "Month":
        # extract month from date
        value = csvDict["Month"].split("-")[-1]
    elif header == "Year":
        # extract year from date
        value = str( 2000 + int(csvDict["Month"].split("-")[0]) )
    elif header in ["MaxSeats", "AllFlights"]:
        # numerical values
        num = int( csvDict[header].replace(" ", "") ) #remove whitespaces
        if bin_size == 0:
            # binning not required
            value = num
        else:
            # binning required
            i = int(num / bin_size)
            value = str(bin_size*i) + "-" + str(bin_size*(i+1))
    else:
        # other values
        value = csvDict[header]

    return value


def boundary_values(csvFile, header):
    """
    csvFile - directory of csvFile to be read
    header - one of the numerical headers in the original csv file, assume valid

    returns [min value, max value] in the csv file given the header
    """

    f = open(csvFile)
    reader = DictReader(f)
    
    firstLine = reader.next()
    minValue = maxValue = value_of(firstLine, header)

    for row in reader:
        value = value_of(row, header) 
        if value < minValue:
            # new minimum
            minValue = value
        elif value > maxValue:
            # new maximum
            maxValue = value

    return [minValue, maxValue]


def bin_size(minimum, maximum):
    """
    minimum, maximum - integers representing minimum and maximum numbers

    return an appropriate size for each bin
    """

    size = maximum - minimum
    mag = int(log10(size)) # order of magnitude of the size
    binsize = int(round(size/10, -(mag-1))) # binsize set order less by 1 of the original size
    return binsize
    

def unique_values(csvFile, header):
    """
    csvFile - directory of csvFile to be read
    header - one of the non-numerical headers in the original csv file, assume valid

    return a list of unique values in the csv file given the header
    """

    if header == "Month":
        # return months in correct order directly
        return ["Jan", "Feb", "Mar", "Apr",
                "May", "Jun", "Jul", "Aug",
                "Sep", "Oct", "Nov", "Dec"]
    
    f = open(csvFile)
    uniques = set()
    reader = DictReader(f)
    # iterate and keep track of unique values
    for row in reader:
        value = value_of(row, header)
        uniques.add(value)

    return sorted(list(uniques))


def parse_data(csvFile, rowType, colType, valueType, filterType = "", filterOptions = []):
    """
    csvFile - directory of csvFile to be read
    rowType - a string specifying the rows
    colType - a string specifying the columns
    filterType - an optional string sepecifying the type to filter
    filterOptions - contains either [min, max] or [values]

    headers must be the exact string in the headers of the csv file, except "month" and "year"

    returns (sorted row headers, sorted column headers, 2d dictionary data)
    each cell in the 2d-dictionary is a list of values ( [] for no values )
    """

    row_binsize = col_binsize = 1
    
    # get the headers
    if rowType in ["MaxSeats", "AllFlights"]:
        # get the bins
        (row_minvalue, row_maxvalue) = boundary_values(csvFile, rowType)
        row_binsize = bin_size(row_minvalue, row_maxvalue)
        rows = []
        i = row_minvalue
        while i + row_binsize < row_maxvalue:
            rows.append( str(i) + "-" + str(i + row_binsize) )
            i += row_binsize
        rows.append( str(i) + "-" + str(min(row_maxvalue, i + row_binsize)) )
    else:
        # get all unique values
        rows = unique_values(csvFile, rowType)

    if colType in ["MaxSeats", "AllFlights"]:
        # get the bins
        (col_minvalue, col_maxvalue) = boundary_values(csvFile, colType)
        col_binsize = bin_size(col_minvalue, col_maxvalue)
        cols = []
        i = col_minvalue
        while i + col_binsize < col_maxvalue:
            cols.append( str(i) + "-" + str(i + col_binsize) )
            i += col_binsize
        cols.append( str(i) + "-" + str(min(col_maxvalue, i + col_binsize)) )
    else:
        # get all unique values
        cols = unique_values(csvFile, colType)
    
    f = open(csvFile)
    reader = DictReader(f)
    keys = reader.fieldnames

    # 2-dimensional defaultdict of lists
    data = defaultdict(lambda: defaultdict(list))

    for line in reader:
        # determine key used for rows, columns and values to put in
        rowKey = value_of(line, rowType, row_binsize)
        colKey = value_of(line, colType, col_binsize)
        value = value_of(line, valueType)
        if filterType in ["MaxSeats", "AllFlights"]:
            # number range as filter
            toFilter = value_of(line, filterType)
            if (toFilter > int(filterOptions[0])) and (toFilter < int(filterOptions[1])):
                data[rowKey][colKey].append(value)
        elif filterType:
            # selections as filter
            toFilter = value_of(line, filterType)
            if toFilter in filterOptions:
                data[rowKey][colKey].append(value)
        else:
            # no filter
            data[rowKey][colKey].append(value)

    return (rows, cols, data)


def generate_series(rows, cols, data, aggOption):
    """
    rows - the sorted row headers
    cols - the sorted column headers
    data - a 2d dictionary containing all the data to be displayed
    aggOption - be one of "count", "sum", "average", "min", "max"

    returns the data array for Highcharts
    """
    series = []
    for i in range(len(cols)):
        for j in range(len(rows)):
            l = data[rows[j]][cols[i]];
            # treat [] as empty, if not, aggregate with option provided
            if len(l) != 0:
                if aggOption == "count":
                    series.append([ i, j, len(l) ])
                elif aggOption == "sum":
                    series.append([ i, j, sum(l) ])
                elif aggOption == "avg":
                    avg = sum(l) / float(len(l))
                    series.append([ i, j, round(avg, 2) ])
                elif aggOption == "min":
                    series.append([ i, j, min(l) ])
                elif aggOption == "max":
                    series.append([ i, j, max(l) ])

    return series



if __name__ == "__main__":

    form = FieldStorage()

    row = form["row"].value
    col = form["col"].value
    val = form["val"].value
    agg = form["agg"].value
    
    if "fil" in form:
        # determine the filter and its options
        fil = form["fil"].value
        if "min" in form:
            filOptions = [form["min"].value, form["max"].value]
        elif "opt" in form:
            filOptions = form.getlist("opt")
        else:
            filOptions = []
        rows, cols, data = parse_data("../RawData/Data.csv", row, col, val, fil, filOptions)
    else:
        # no filter
        rows, cols, data = parse_data("../RawData/Data.csv", row, col, val)


    # generate Highcharts options 
    options = { "chart": {"type": "heatmap",
                      "height": 250*log(len(rows))}, #dynamic height respect to number of rows
            "title": {"text": row + " vs. " + col},
            "xAxis": {"categories": cols},
            "yAxis": {"categories": rows}
            }


    s = {}
    s["name"] = "Number of Flights"
    s["borderWidth"] = 1
    s["data"] = generate_series(rows, cols, data, agg)

    options["series"] = [s]

    print "Content-Type: text/json"
    print  
    print json.dumps(options)